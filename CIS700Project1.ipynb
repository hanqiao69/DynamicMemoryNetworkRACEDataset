{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIS700Project1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNUTURotFkkeyGlCP6v3D5p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2ycbLfQpSQlT","colab_type":"code","outputId":"c4a97a55-9a2d-409a-cdbd-5b3760a8e2ac","executionInfo":{"status":"ok","timestamp":1584584677644,"user_tz":240,"elapsed":31156,"user":{"displayName":"Qiao Han","photoUrl":"","userId":"07933257086038261786"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"82bZTpisSxWJ","colab_type":"code","outputId":"67e3d594-24e6-4eec-cab0-973c7440d9a0","executionInfo":{"status":"ok","timestamp":1584584686143,"user_tz":240,"elapsed":16276,"user":{"displayName":"Qiao Han","photoUrl":"","userId":"07933257086038261786"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["%cd '/content/drive/My Drive/Spring2020/CIS700-001/project_1/to_submit'\n","!pip install sentencepiece"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Spring2020/CIS700-001/project_1/to_submit\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 25.6MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.85\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fPPBrZsKTDEC","colab_type":"code","outputId":"2dcd4a43-57d9-4a24-a5a4-0fc58c3a5d02","executionInfo":{"status":"ok","timestamp":1584584699360,"user_tz":240,"elapsed":27204,"user":{"displayName":"Qiao Han","photoUrl":"","userId":"07933257086038261786"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"source":["from DMN_Plus_RACE2 import *"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"WzisuXZ_TS_r","colab_type":"code","colab":{}},"source":["HOMEWORK_FOLDER = '/content/drive/My Drive/Spring2020/CIS700-001/project_1/to_submit/'\n","CHECKPOINT_PATH = HOMEWORK_FOLDER + 'dmn_race_checkpt.pth'\n","dset_dict, vocab_dict = {}, {}\n","# for task_id in range(1, 21):\n","#     dset_dict[task_id] = BabiDataset(task_id)\n","#     vocab_dict[task_id] = len(dset_dict[task_id].QA.VOCAB)\n","for run in range(1):\n","    # for task_id in range(1, 21):\n","      dset = RACEDataset(mode='train')\n","      vocab_size = len(dset.QA.VOCAB)\n","      hidden_size = 80\n","      print('debug model size: ', vocab_size, hidden_size)\n","      model = DMNPlus(hidden_size, vocab_size, num_hop=3, qa=dset.QA)\n","      model # .cuda()\n","      torch.save(model.state_dict(), CHECKPOINT_PATH)\n","      early_stopping_cnt = 0\n","      early_stopping_flag = False\n","      best_acc = 0\n","      optim = torch.optim.Adam(model.parameters())\n","\n","      for epoch in range(256):\n","          dset.set_mode('train')\n","          train_loader = DataLoader(dset, batch_size=2, shuffle=True, collate_fn=pad_collate)\n","\n","          model.train()\n","          if not early_stopping_flag:\n","              total_acc = 0\n","              cnt = 0\n","              for batch_idx, data in enumerate(train_loader):\n","                  optim.zero_grad()\n","                  contexts, questions, answers, options = data\n","                  # print('debug msg data shape: ', contexts.shape, questions.shape, answers.shape)\n","                  batch_size = contexts.size()[0]\n","                  contexts = contexts.long() # .cuda()\n","                  questions = questions.long() # .cuda()\n","                  answers = answers # .cuda()\n","\n","                  loss, acc = model.get_loss(contexts, questions, answers, options)\n","                  loss.backward()\n","                  total_acc += acc * batch_size\n","                  cnt += batch_size\n","\n","                  if batch_idx % 20 == 0:\n","                      print(f'Epoch {epoch}] [Training] loss : {loss.item(): {10}.{8}}, '\n","                            f'acc : {total_acc / cnt: {5}.{4}}, batch_idx : {batch_idx}')\n","                  optim.step()\n","                  if batch_idx % 100 == 0:\n","                      torch.save(model.state_dict(), CHECKPOINT_PATH)\n","\n","              dset.set_mode('valid')\n","              valid_loader = DataLoader(dset, batch_size=2, shuffle=False, collate_fn=pad_collate)\n","\n","              model.eval()\n","              total_acc = 0\n","              cnt = 0\n","              for batch_idx, data in enumerate(valid_loader):\n","                  contexts, questions, answers, options = data\n","                  batch_size = contexts.size()[0]\n","                  contexts = contexts.long() # .cuda()\n","                  questions = questions.long() # .cuda()\n","                  answers = answers # .cuda()\n","\n","                  _, acc = model.get_loss(contexts, questions, answers, options)\n","                  total_acc += acc * batch_size\n","                  cnt += batch_size\n","\n","              total_acc = total_acc / cnt\n","              if total_acc > best_acc:\n","                  best_acc = total_acc\n","                  best_state = model.state_dict()\n","                  early_stopping_cnt = 0\n","              else:\n","                  early_stopping_cnt += 1\n","                  if early_stopping_cnt > 20:\n","                      early_stopping_flag = True\n","\n","              print(f'[Run {run}, Epoch {epoch}] [Validate] Accuracy : {total_acc: {5}.{4}}')\n","              with open(HOMEWORK_FOLDER + 'log_b128.txt', 'a') as fp:\n","                  fp.write(\n","                      f'[Run {run}, Epoch {epoch}] [Validate] Accuracy : {total_acc: {5}.{4}}' + '\\n')\n","              if total_acc == 1.0:\n","                  break\n","          else:\n","              print(\n","                  f'[Run {run}] Early Stopping at Epoch {epoch}, Valid Accuracy : {best_acc: {5}.{4}}')\n","              break\n","\n","      dset.set_mode('test')\n","      test_loader = DataLoader(dset, batch_size=2, shuffle=False, collate_fn=pad_collate)\n","      test_acc = 0\n","      cnt = 0\n","\n","      for batch_idx, data in enumerate(test_loader):\n","          contexts, questions, answers, options = data\n","          batch_size = contexts.size()[0]\n","          contexts = contexts.long() # .cuda()\n","          questions = questions.long() # .cuda()\n","          answers = answers # .cuda()\n","\n","          model.load_state_dict(best_state)\n","          _, acc = model.get_loss(contexts, questions, answers, options)\n","          test_acc += acc * batch_size\n","          cnt += batch_size\n","      print(f'[Run {run}, Epoch {epoch}] [Test] Accuracy : {test_acc / cnt: {5}.{4}}')\n","      os.makedirs('models', exist_ok=True)\n","      with open(f'models/epoch{epoch}_run{run}_acc{test_acc / cnt}.pth', 'wb') as fp:\n","          torch.save(model.state_dict(), fp)\n","      with open(HOMEWORK_FOLDER + 'log_b128.txt', 'a') as fp:\n","          fp.write(f'[Run {run}, Epoch {epoch}] [Test] Accuracy : {total_acc: {5}.{4}}' + '\\n')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rDd1yiPCUNyV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}